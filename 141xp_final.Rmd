---
title: |
  | \vspace{5cm} Analyzing MLB Draft Biases and Modeling Player Success
  | using Wins Above Replacement
subtitle: |
  | \vspace{1cm} STATS 141XP Final Project
author: |
  | Peter DePaul, Anish Ravilla, Robin Lee
  | Kevin Kim, Alan Wong, Hongye Zheng
date: "`r Sys.Date()`" 
abstract: "In Major League Baseball, the First Year Player Draft is the primary system for teams to select amateur baseball players from high school, colleges, and other amateur baseball clubs. With this report, we seek to not only identify attributes and physical characteristics that influence a draftee's selection, but also develop a model to predict who ultimately succeeds. We explore recurring trends among drafted players—such as their patterns in home state, prior experience, and time in the MLB—and analyze their relationship with Wins After Replacement. By quantifying success as a player's overall WAR, we also construct a Gradient Boosted Decision Tree model for predicting WAR. Our model tends to accurately predict which players perform poorly in their careers, but struggles to predict players with average and high performing careers. Furthermore, we discover that there is some bias favoring players from college and certain home states which may affect their draft potential. While there is some statistical evidence suggesting a player's position and debut age correlates with their WAR, we have found little success predicting a player's WAR using their draft information and demographics. Ultimately, the charm and excitement of Major League Baseball is in its unpredictability—where success and talent is not defined by a quantifiable attribute or a specific set of traits."
output: 
  bookdown::pdf_document2:
    fig_width: 12
    toc: no
    number_sections: true
bibliography: references.bib
linkcolor: blue
urlcolor: blue
citecolor: blue
link-citations: yes
editor_options: 
  markdown: 
    wrap: 72
---

\newpage

```{=latex}
\hypersetup{linkcolor=black}
\setcounter{tocdepth}{4}
\tableofcontents
\hypersetup{linkcolor=blue}
```
\newpage

```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, cache = TRUE)
#install.packages("bookdown")
library(bookdown)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(corrplot)
library(data.table)
library(tidyverse)
library(tidymodels)
library(xgboost)
library(doParallel)
library(vip)
library(caret)
library(Boruta)
library(randomForest)
library(kableExtra)
library(leaflet)
library(maps)
library(mapdata)
library(mapproj)
library(reshape2)
#Load in datasets
draft_info <- fread('Data/clean_draft.csv')
draft_info <- 
  draft_info %>% 
  mutate(mlb_years = ifelse(mlb_played_first == 0 & mlb_played_last == 0, 0,
                            (mlb_played_last - mlb_played_first) + 1 ) )
## below _df objects contain data ONLY from players with at least 1 game in the
## MLB
bat_draft_df <- fread('Data/bat_subset.csv')
pitch_draft_df <- fread('Data/pitch_subset.csv')
```

# Introduction

In the world of professional baseball---specifically Major League
Baseball (MLB)---the First Year Player Draft is a significant moment
where teams meticulously evaluate and select amateur baseball players
from high schools, colleges, and other amateur baseball clubs. However,
even though the selection process should technically be based on
objective and impartial reasoning, we are confident that various
multifaceted biases subtly influence the decisions made by scouts and
team executives [@caporale2013].

## Background

The baseball draft is a process in which the MLB's 30 professional
baseball franchises gather together to draft amateur players, which
mainly consist of players from the high school and college circuits
[@staudohar2006]. Teams take turns picking players for their roster.
Keep in mind that some players are drafted more than once. In this case,
players are usually drafted out of high school, but they decide not to
sign and instead play college baseball; they re-enter the draft after
completing college.

\smallskip

Teams are awarded draft picks based on a **draft lottery**, with the
teams that did not make the playoffs the previous year being entered
into the lottery, and are given the opportunity to go first in the
draft. The draft currently undergoes 20 rounds of selections, where each
team gets to pick a player of interest for their roster. This draft,
occurring in June, is also known as the **First-Team Player Draft**,
where players who enter are typically high school or community
college/four-year college graduates, and have never played for any
professional baseball team [@garmon2012].

## Variable Overview

By implementing statistical data analysis, we seek to investigate how a
scout's perception of talent and potential is influenced by a
prospective player's attributes---such as their age, position, dominant
hand, and educational background [@conforti2022]. Furthermore, in order
to quantify the success of drafted players, we utilize their **Wins
Above Replacement (WAR)**. For a comprehensive overview of all
parameters, see Table \@ref(tab:example). We accessed our data from Bill
Petti's [BaseballR](https://billpetti.github.io/baseballr/) package.

We hope to identify biases that influence when a player is drafted, and
determine whether these decisions are meritorious based on said player's
performance [@crotin2023].

```{=tex}
\begin{table}[ht]
  \centering
  \begin{tabular}{|c|c|c|}
    \hline
    Label & Description & Unit of Measure \\
    \hline
    fg$\_$playerID & Player ID & Numeric \\
    Name & Player name & Character \\
    fWAR & Wins Above Replacement & Numeric \\
    pick$\_$round & Which round a player is picked & Numeric \\
    pick$\_$number & Which number a player is picked & Numeric \\
    year & Year a player is picked & Numeric \\
    person$\_$birth$\_$state$\_$province & State or province the player is born & Character \\
    person$\_$height & Height of player & Numeric \\
    person$\_$weight & Weight of player & Numeric \\
    person$\_$primary$\_$position$\_$abbreviation & Player's primary position & Character \\
    person$\_$bat$\_$side$\_$code & Player's batting side (L/R) & Binary \\
    person$\_$pitch$\_$hand$\_$code & Player's pitching hand (L/R) & Binary \\
    mlb$\_$played$\_$first & Year of first MLB game & Numeric \\
    mlb$\_$played$\_$last & Year of last MLB game & Numeric \\
    high$\_$school & Player went to high school & Binary \\
    home$\_$state & Player's home state & Character \\
    \hline
  \end{tabular}
  \caption{Variable Overview}
  \label{tab:example}
\end{table}
```
# Exploratory Data Analysis

## Relationship between drafting High School or College Players

In order to analyze the relationship between draft round and high school
status, we created a barplot showing the total number of draftees by
round with colors denoting high school status when drafted. By analyzing
this barplot [see Figure \@ref(fig:barplot)], we can see that as you get
further into the first 10 rounds that siginficantly less high school
players are drafted.

```{r barplot, fig.align='center', fig.cap="Frequency of High School Players by Round", warning=FALSE}
# Create a dataframe with state naming data
state_data <- data.frame(names = state.name, abbreviation = tolower(state.abb))

draft_info <- 
  draft_info %>% 
  left_join(state_data, by = c("home_state" = "abbreviation")) %>%
  select(-home_state) %>%
  rename(home_state = names) %>% 
  drop_na(home_state)
# Subset the data to only players drafted in the first 10 rounds
first_10 <- 
  draft_info %>% 
  filter(as.integer(pick_round) %in% c(1:10)) %>% 
  drop_na(high_school) %>% 
  group_by(pick_round, high_school) %>% 
  summarise(num_players = n()) %>% 
  arrange(desc(num_players)) %>% 
  ungroup() %>% 
  mutate(pick_round = factor(pick_round, levels = c(1:10)),
         high_school = as.factor(ifelse(high_school == "Yes", "High School", 
                                        "College")))

hs_by_round_plot <-
  ggplot(first_10, aes(x = pick_round, y = num_players, fill = high_school)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(y = "Total Players", x = "Draft Round", 
       title = "Number of Draftees by Pick and Round",
       fill = "High School Player") +
  theme_minimal()
hs_by_round_plot
```

## Histogram of Time to Play First MLB Game

In order to analyze the number of years before a draftee played their
first MLB game, we calculated the number of years between a player's
first MLB game and the year they were drafted.

\bigskip

```{r histograms, fig.cap = "Histograms of Years before First MLB Game"}
#Created a new variable for each dataset that gives the number of years it took for a player 
#to play their first MLB game
bat_draft_df$DifferenceYearsDraftFGPlayed <- bat_draft_df$mlb_played_first - bat_draft_df$year
pitch_draft_df$DifferenceYearsDraftFGPlayed <- pitch_draft_df$mlb_played_first - pitch_draft_df$year
plot1 <- ggplot(bat_draft_df, aes(x = DifferenceYearsDraftFGPlayed)) +
  geom_histogram(binwidth = 0.5, fill = "skyblue", color = "black", alpha = 0.8) +
  labs(title = "Years for a Batting Draftee to Play Their First MLB Game", 
       x = "# of Years", y = "Frequency") +
  theme_minimal()

plot2 <- ggplot(pitch_draft_df, aes(x = DifferenceYearsDraftFGPlayed)) +
  geom_histogram(binwidth = 0.5, fill = "orange", color = "black", alpha = 0.8) +
  labs(title = "Years for a Pitching Draftee to Play Their First MLB Game", 
       x = "# of Years", y = "Frequency") + 
  theme_minimal()
grid.arrange(plot1, plot2, nrow = 1)
```

By analyzing these two histograms [see Figure \@ref(fig:histograms)],
the number of years for a batting draftee to play their first MLB game
is similar to the number of years for a pitching draftee. Both datasets
are slightly right-skewed, with most people playing their first game
between 3-5 years after their draft.

## Relationship between Weight and Height

We also investigated the relationship between weight and height for both
batting and pitching draftees. By creating a scatterplot of both
datasets, we not only mapped each individual person's attributes, but
also plotted the mean weight/height and performed a simple linear
regression to determine the overall trend.

\bigskip

```{r scatterplots, fig.cap = "Scatterplots of Mean vs. Weight", warning=FALSE}
plot1 <- ggplot(bat_draft_df, aes(x = person_weight, y=person_height)) +
  geom_point(fill="skyblue", shape=21, size=2, alpha = 0.8) +
  geom_hline(yintercept = mean(bat_draft_df$person_height,na.rm=T), 
             color = "red", linetype = "dashed", alpha = 0.8) + 
  geom_vline(xintercept = mean(bat_draft_df$person_weight,na.rm=T), 
             color = "blue", linetype = "dashed", alpha = 0.8) +
  geom_text(aes(x = mean(bat_draft_df$person_weight,na.rm=T) + 1, 
                y = mean(bat_draft_df$person_height,na.rm=T), 
                label = paste("Mean Weight")), 
            color = "blue", hjust = 0, vjust = -15, alpha = 0.8) +  
  geom_text(aes(x = mean(bat_draft_df$person_weight,na.rm=T), 
                y = mean(bat_draft_df$person_height,na.rm=T) - 1, 
                label = paste("Mean Height")), 
            color = "red", hjust = -3, vjust = 0, alpha = 0.8) +  
  geom_smooth(method = "lm", se = FALSE, color = "black", alpha = 0.8) +
  labs(title = "Weight vs. Height (Batters)", 
       x = "Draftee Weight", y = "Draftee Height") +
  theme_minimal()

plot2 <- ggplot(pitch_draft_df, aes(x = person_weight, y=person_height)) +
  geom_point(fill="orange", shape=21, size=2, alpha = 0.8) +
  geom_hline(yintercept = mean(pitch_draft_df$person_height,na.rm=T), 
             color = "red", linetype = "dashed", alpha = 0.8) + 
  geom_vline(xintercept = mean(pitch_draft_df$person_weight,na.rm=T), 
             color = "blue", linetype = "dashed", alpha = 0.8) +
  geom_text(aes(x = mean(pitch_draft_df$person_weight,na.rm=T) + 1, 
                y = mean(pitch_draft_df$person_height,na.rm=T), 
                label = paste("Mean Weight")), 
            color = "blue", hjust = 0, vjust = -16, alpha = 0.8) +  
  geom_text(aes(x = mean(pitch_draft_df$person_weight,na.rm=T), 
                y = mean(pitch_draft_df$person_height,na.rm=T) - 1, 
                label = paste("Mean Height")), 
            color = "red", hjust = -2.8, vjust = 0, alpha = 0.8) +  
  geom_smooth(method = "lm", se = FALSE, color = "black", alpha = 0.8) +
  labs(title = "Weight vs. Height (Pitchers)", 
       x = "Draftee Weight", y = "Draftee Height") +
  theme_minimal()

grid.arrange(plot1, plot2, nrow = 1)
```

Comparing these two plots [see Figure \@ref(fig:scatterplots)], the mean
weight for batting draftees is slightly smaller than the mean weight for
pitching draftees. Likewise, the mean height of batting draftees is also
slightly smaller than the mean height of their pitching counterparts. We
can expect the average batting draftee to be slightly shorter and
lighter than the average pitching draftee.

## Correlation Heatmap

The correlation between pick round, year, height, weight, and WAR for
both player categories is:

```{r correlation,warning=FALSE,fig.align='center', fig.cap = "Correlation Plots for Pitching and Batting", fig.height=3.5}
par(mfrow=c(1,2))
# %>% full_join(pitch_draft_df)
bat_draft_df1 <- bat_draft_df %>%
  mutate(pick_round=as.numeric(pick_round)) %>% 
  drop_na()
correlation_matrix <- cor(bat_draft_df1[, c(4,5,7,9,10)]) 
corrplot(correlation_matrix, method = "color")
title("Correlation Plot (Batting)",line = 3,adj=0)
#title(sub = "Plot 5: Correlation Plot of Batters", line=4.5)

pitch_draft_df1 <- pitch_draft_df %>%
  mutate(pick_round=as.numeric(pick_round)) %>% 
  drop_na()
correlation_matrix <- cor(pitch_draft_df1[, c(4,5,7,9,10)]) 
corrplot(correlation_matrix, method = "color")
title("Correlation Plot (Pitching)",line = 3,adj=0)
#title(sub = "Plot 6: Correlation Plot of Pitchers", line=4.5)
```

As expected [see Figure \@ref(fig:correlation)], there is a strong
correlation between a person's height and their weight. For pitching,
there is a small positive correlation between a player's height and
their WAR; for batting, there is a negative correlation between a
player's height and their WAR. We see there is no correlation between a
batting draftees' weight and WAR, but there is a slight positive
correlation for a pitching draftee.

## Home State Frequency Heatmap

In order to investigate which state produces the most draftees, we
construct a frequency heatmap:

```{r statemap,fig.height=3, fig.width=6.5, fig.align='center', fig.cap = "Frequency Heatmap of Players per State"}

# Create a frequency of the states of drafted draft_info
state_freq <- table(draft_info$home_state)

# Convert the table to a datafram
state_freq_df <- 
  data.frame(region = tolower(names(state_freq)), # convert states to lowercase
             frequency = as.numeric(state_freq)) %>% # draft_info from each state
  arrange(desc(frequency)) %>% # arrange in descending order of draft_info drafted
  filter(!(region %in% c("hawaii", "alaska"))) # View only contiguous U.S.

# Mapping data for the United States map
states <- map_data("state")

# Create a dataframe with the coordinates, and the frequencies in each state
map.df <- 
  merge(states, state_freq_df, by="region", all.x=T) %>% 
  rename(longitude = long, latitude = lat) %>% 
  select(-subregion) %>% 
  filter(region %in% state_freq_df$region)

map.df <- map.df[order(map.df$order),] # make sure the dataframe is ordered

# Create a heat map of the draft_info drafted by home_state
home_heat_map <- 
  ggplot(map.df, aes(x = longitude, y = latitude, group = group)) +
  geom_polygon(aes(fill=frequency)) +
  geom_path() +
  scale_fill_gradient(low = "white", high = "darkred", 
                      name = "Players Drafted") +
  labs(title = "Heat Map of Drafted Players") +
  theme(plot.title = element_text(hjust = 0.5))
home_heat_map
```

From our state map [see Figure \@ref(fig:statemap)], we can see that
most players drafted are originally from California, with Texas and
Florida as the other two primary home states. We can attribute this
trend to weather, as these states tend to have higher temperatures and
little-to-no snow compared to East, Midwest, and Northwest, which allows
people to play baseball all year long and for youth leagues to have more
flexibility with their seasons. These states also have relatively large
populations, which could easily explain why the most draftees emerge
from these states.

## Relationship between Time in MLB and WAR

Exploring how the length of player's career affects their WAR, we
construct the following scatterplot:

\bigskip

```{r mlbwar, fig.cap = "Relationship between Time Played in MLB vs. WAR", fig.height=3}
players <- bind_rows(bat_draft_df, pitch_draft_df) %>% 
  arrange(desc(fWAR)) %>% 
  distinct(person_id, .keep_all = T)
players$time_played <- (players$mlb_played_last - players$mlb_played_first) + 1
ggplot(players, aes(x = time_played, y=fWAR)) +
  geom_point(fill="white", shape=21, size=2, alpha = 0.8) +
  geom_hline(yintercept = mean(players$fWAR,na.rm=T), 
             color = "red", linetype = "dashed", alpha = 0.8) + 
  geom_vline(xintercept = mean(players$time_played,na.rm=T), 
             color = "blue", linetype = "dashed", alpha = 0.8) +
  geom_text(aes(x = mean(players$time_played,na.rm=T)+0.5, 
                y = mean(players$fWAR,na.rm=T)+40, 
                label = paste("Mean Time")), 
            color = "blue", hjust = 0, vjust = -10, alpha = 0.8) +  
  geom_text(aes(x = mean(players$time_played,na.rm=T)+8, 
                y = mean(players$fWAR,na.rm=T)+5, 
                label = paste("Mean WAR")), 
            color = "red", hjust = -4, vjust = 0, alpha = 0.8) +
  labs(title = "Total Time in MLB vs. WAR", 
       x = "Total Time Played in MLB", y = "Wins Above Replacement") +
  theme_minimal()
```

By comparing each player's total time played in MLB and WAR [see Figure
\@ref(fig:mlbwar)], we can see that the length of a player's career does
not always equate to a high WAR. However, there does seem to be an
upward trend, which makes sense as we expect a player to win more as
they play longer.

\newpage

# Analysis and Model of Player Success

## Who is Successful?

### How often do Draftees make it to the MLB?

In baseball, not every player who is drafted ultimately plays in the
major leagues. In order to identify who is ultimately successful, we
need to first identify the players that even make it to the MLB.

```{r piechart, fig.cap="Pie Chart of Draftees MLB Status", out.height="40%", out.width="40%",fig.align = 'center'}
# load in full batters draft data
bat_draft <- 
  fread('Data/batters/batters_full_draft.csv') %>%
  select(fg_playerID, person_id, person_full_name, fWAR, pick_round,
         pick_number, year, person_birth_state_province,
         person_height, person_weight, home_state,
         person_primary_position_abbreviation,
         person_bat_side_code, person_pitch_hand_code,
         mlb_played_first, mlb_played_last, high_school,
         birth_year)
# load in full pitchers draft data
pitch_draft <- 
  fread('Data/pitchers/pitchers_full_draft.csv') %>%
  select(fg_playerID, person_id, person_full_name, fWAR, pick_round,
         pick_number, year, person_birth_state_province,
         person_height, person_weight, home_state,
         person_primary_position_abbreviation,
         person_bat_side_code, person_pitch_hand_code,
         mlb_played_first, mlb_played_last, high_school, birth_year
         )

# bind them into players data
players <- 
  bind_rows(pitch_draft, bat_draft) %>% 
  mutate(pick_round = as.numeric(pick_round)) %>% 
  filter(pick_round %in% c(1:100)) %>% 
  group_by(person_id) %>% 
  # Choose the player's most recent draft year (if drafted more than once)
  dplyr::slice(which.max(year)) %>% 
  ungroup() %>% 
  # Add these classifier variables for data table presentation
  mutate(less_five_war = ifelse(fWAR < 5, 1, 0),
         five_to_10 = ifelse(fWAR >= 5 & fWAR < 10, 1, 0),
         ten_to_15 = ifelse(fWAR >= 10 & fWAR < 15, 1, 0),
         fifteen_to_20 = ifelse(fWAR >= 15 & fWAR < 20, 1, 0),
         twenty_to_25 = ifelse(fWAR >= 20 & fWAR <= 25, 1, 0),
         more_than_25 = ifelse(fWAR > 25, 1, 0),
         yrs_before_debut = mlb_played_first - year,
         time_played = (mlb_played_last - mlb_played_first) + 1,
         debut_age = mlb_played_first - birth_year,
         draft_age = debut_age - yrs_before_debut) %>% 
  arrange(desc(fWAR))

# fWAR info by draft year
fwar_info_by_year <-
  players %>% 
  group_by(year) %>% 
  summarise(`Less than 5 fWAR` = round(sum(less_five_war) / n() * 100, 2),
            `5-10 fWAR` = round(sum(five_to_10) / n() * 100, 2),
            `10-15 fWAR` = round(sum(ten_to_15) / n() * 100, 2),
            `15-20 fWAR` = round(sum(fifteen_to_20) / n() * 100, 2),
            `20-25 fWAR` = round(sum(twenty_to_25) / n() * 100, 2),
            `Greater than 25 fWAR` = round(sum(more_than_25) / n() * 100, 2)) %>% 
  mutate(`Less than 5 fWAR` = paste(`Less than 5 fWAR`, "%", sep = " "),
         `5-10 fWAR` = paste(`5-10 fWAR`, "%", sep = " "),
         `10-15 fWAR` = paste(`10-15 fWAR`, "%", sep = " "),
         `15-20 fWAR` = paste(`15-20 fWAR`, "%", sep = " "),
         `20-25 fWAR` = paste(`20-25 fWAR`, "%", sep = " "),
         `Greater than 25 fWAR` = paste(`Greater than 25 fWAR`, "%", sep = " "))

# round_numbers <- 
#   as.numeric(unique(players$pick_round[which(as.numeric(players$pick_round) %in% c(1:100))])) %>% 
#   sort()

# # fWAR info summarised by draft round
# fwar_info_by_round <- 
#   players %>% 
#   mutate(pick_round = factor(pick_round, levels = round_numbers)) %>% 
#   group_by(pick_round) %>% 
#   summarise(`Less than 5 fWAR` = round(sum(less_five_war) / n() * 100, 2),
#             `5-10 fWAR` = round(sum(five_to_10) / n() * 100, 2),
#             `10-15 fWAR` = round(sum(ten_to_15) / n() * 100, 2),
#             `15-20 fWAR` = round(sum(fifteen_to_20) / n() * 100, 2),
#             `20-25 fWAR` = round(sum(twenty_to_25) / n() * 100, 2),
#             `Greater than 25 fWAR` = round(sum(more_than_25) / n() * 100, 2)) %>% 
#   mutate(`Less than 5 fWAR` = paste(`Less than 5 fWAR`, "%", sep = " "),
#          `5-10 fWAR` = paste(`5-10 fWAR`, "%", sep = " "),
#          `10-15 fWAR` = paste(`10-15 fWAR`, "%", sep = " "),
#          `15-20 fWAR` = paste(`15-20 fWAR`, "%", sep = " "),
#          `20-25 fWAR` = paste(`20-25 fWAR`, "%", sep = " "),
#          `Greater than 25 fWAR` = paste(`Greater than 25 fWAR`, "%", sep = " "))

# Reload in the untouched draft_info
draft_info <- fread('Data/draft_data.csv') %>% 
  mutate(mlb_played_first = year(person_mlb_debut_date),
         high_school = ifelse(str_detect(school_name, "\\sHS") == TRUE, "Yes", 
                              "No"),
         person_height = str_replace_all(person_height, "\"$", "")) %>% 
  replace_na(list(home_state = "None", mlb_played_first = 0)) %>% 
  mutate(mlb_played_last = ifelse(mlb_played_first == 0, 0, 
                           year(person_last_played_date)),
         made_mlb = ifelse(mlb_played_first == 0, 0, 1)) %>% 
  replace_na(list(mlb_played_last = 2023)) %>% 
  # Remove variables of no interest
  select(-person_link, -c(person_use_name:person_gender),
         -c(person_name_slug:person_init_last_name), 
         -c(person_name_matrilineal:home_city), -c(home_country, school_state),
         -c(person_xref_ids:person_death_country), -person_name_title, -team_id,
         -person_name_suffix, -c(team_link:team_spring_league_abbreviation), 
         -headshot_link, home_state)

# Full Draft information breakdown by draft year
mlb_info <- 
  draft_info %>% 
  # mutate to a factor for sorting purposes
  mutate(pick_round = as.numeric(draft_info$pick_round))  %>% 
  filter(pick_round %in% c(1:100)) %>% 
  group_by(person_id) %>% 
  dplyr::slice(which.max(year)) %>% 
  ungroup() %>%  
  summarise(`Drafted` = n(), # total number of draftees
            `Made MLB` = sum(made_mlb), # number of draftees to make MLB
            # percent of players to make the MLB
            `% Made MLB` = round( (`Made MLB` / `Drafted`) * 100, 2),
            # percent of players to NOT make the MLB
            `% Missed MLB` = round((100 - `% Made MLB`), 2))

mlb_info_long <- 
  mlb_info %>% 
  pivot_longer(cols = c( `Made MLB`,  `Drafted`), names_to = "Category", 
               values_to = "Total Players")

pie_chart <-
  ggplot(data = mlb_info_long, aes(x = "", y = `Total Players`, fill = Category)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar("y", start = 0) +
  theme_void() +
  labs(title = "Pie Chart of MLB Status") + 
  geom_text(aes(label = c(paste(mlb_info$`% Made MLB`, "%", sep = ""), paste(mlb_info$`% Missed MLB`, "%", sep = "")), hjust = 0.75, vjust = -1), size = 5.3)
pie_chart

# Total fWAR by draft class (year)
total_fwar_by_year <- 
  players %>% 
  group_by(year) %>% 
  summarise(total_fWAR = sum(fWAR)) %>% 
  arrange(desc(total_fWAR)) %>% 
  mutate(rank = c(1:59) )

fwar_levels <- 
  total_fwar_by_year %>% 
  slice_head(n = 10) %>% 
  select(year) %>%  
  unlist() %>% 
  as.character()
```

By looking at the pie chart of whether or not draftees ultimately made
it to the MLB [see Figure \@ref(fig:piechart)], we can see that only
13.06% of players actually received the opportunity to play and a
majority of players miss the major league. We will focus specifically on
the players who made it to the MLB.

### What is the Best Draft Class in MLB History?

We can see from the barplot [see Figure \@ref(fig:draftclassfWAR)] that
the 1965, 1985, and 2002 draft classes are highly successful with each
garnering over 900 total fWAR across the draft class. 1965 includes the
likes of Johnny Bench, Nolan Ryan, and Tom Seaver. Meanwhile 1985
includes Barry Bonds, John Smoltz, and Randy Johnson. 2002 includes Zack
Greinke, Prince Fielder, and Cole Hamels. The thing these drafts share
in common is that they have an abundance of talent, both in terms of
Hall of Famers and depth.

```{r draftclassfWAR, fig.cap="Best Draft Classes by fWAR"}
# Plot of top 10 draft classes by total fWAR
draft_class_fwar <-
  ggplot(total_fwar_by_year %>% 
         slice_head(n = 10), 
       aes(x = factor(rank, levels = c(1:10), labels = fwar_levels), 
           y = total_fWAR
           )
       ) + 
  geom_bar(stat = "identity", fill = "deepskyblue") +
  labs(x = "Draft Class", y = "Total fWAR", 
       title = "Top 10 Draft Classes by Total fWAR") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  geom_text(aes(label = total_fWAR, vjust = -0.5))
draft_class_fwar
```

### What Positions have been Successful?

We are able to see that the positions which are most successful have
often been outfielders (CF or LF), First Basemen (1B), or Third Basemen
(3B) [see Figure \@ref(fig:positionfWAR)]. This can be explained by
First Basemen possessing game changing amount of power hitting, and the
high level fielding roles of outfield and third base.

```{r positionfWAR, fig.cap="Best Draft Classes by Year and Position"}
total_fwar_by_pos_and_year <- 
  players %>% 
  filter(person_primary_position_abbreviation != "P") %>% 
  group_by(year, person_primary_position_abbreviation) %>% 
  summarise(total_fWAR = sum(fWAR)) %>% 
  arrange(desc(total_fWAR)) %>% 
  ungroup() %>% 
  mutate(label = paste(year, person_primary_position_abbreviation, sep = "/"),
         rank = c(1:548))

# total_fwar_by_pos_and_year_pitcher <- 
#   players %>% 
#   filter(person_primary_position_abbreviation == "P") %>% 
#   group_by(year, person_primary_position_abbreviation) %>% 
#   summarise(total_fWAR = sum(fWAR)) %>% 
#   arrange(desc(total_fWAR)) %>% 
#   mutate(label = paste(year))

pos_class_labels <- 
  total_fwar_by_pos_and_year %>% 
  slice_head(n = 10) %>% 
  select(label) %>% 
  unlist() %>% 
  as.character()

# Barplot of total top 10 total fWAR Draft Class/Position Combination
pos_class_fwar <- 
  ggplot(total_fwar_by_pos_and_year %>% 
         slice_head(n = 10), 
       aes(x = factor(rank, levels = c(1:10), labels = pos_class_labels), 
           y = total_fWAR
           )
       ) + 
  geom_bar(stat = "identity", fill = "deepskyblue") +
  labs(x = "Draft Class/Position", y = "Total fWAR", 
       title = "Top 10 Position Classes by Total fWAR") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  geom_text(aes(label = total_fWAR, vjust = -0.5))

pos_class_fwar
```

## Prediction Model

By defining each player's fWAR as the definition of success, we aim to
create a classification model which predicts a players' categorical
level of success only from their physical characteristics, their
demographics, and the characteristics of their draft position.

### Feature Engineering

We believe it would be difficult to predict a player's specific fWAR
numerical value without any informational statistics of their playing
careers. Thus, in order to make this a simpler process, we have come up
with the idea of creating a categorical (factor) variable named
`fWAR_class` with 6 levels:

-   Greater than 25 fWAR
-   20-25 fWAR
-   15-20 fWAR
-   10-15 fWAR
-   5-10 fWAR
-   Less than 5 fWAR

Additionally, in order to assess the impact of where in the draft a
player is picked and its affect on their WAR, we add several binary
variables indicating if the player was any of the following:

-   Player was the #1 overall pick in the draft (`top_pick`)
-   Player was a top 10 overall pick in the draft (`top_10`)
-   Player was a top 25 overall pick in the draft (`top_25`)
-   Player was a top 50 overall pick in the draft (`top_50`)
-   Player was a top 100 overall pick in the draft (`top_100`)

We have also added a few more descriptive characteristics of the
draftees including:

-   `yrs_before_debut` which is the number of years before a player
    debuts in the MLB
-   `draft_age` which is a player's age when they are drafted into the
    MLB
-   `debut_age` which is a player's age when they made their MLB debut

### Feature Selection

Following our feature engineering process, we employ the Boruta feature
selection algorithm in order to ensure we are not using unnecessary
variables in our modeling process. This step will strengthen the
predictive power of our model. The Boruta algorithm is used to confirm
the importance of variables by implementing Random Forest methods based
upon a given classification formula.

**The Boruta process confirms that all predictive features in the data
set are important.**

### Model Creation

For our model, we decide to utilize the XGBoost library in order to
create a gradient boosted decision tree for predicting `fWAR_class`. A
boosted tree is built in sequential order such that it is able to learn
from previous iterations for classification purposes. On top of this,
boosted tree can be tuned to prevent overfitting through the use of tree
depth and penalty functions. We utilize the tidymodels library as well
in order to simplify our workflow and recipe process. Our step-by-step
procedure is as follows:

1.  We split our overall data into a training (70%) and testing (30%)
    data sets stratified by player position.

2.  To take it a step further, we utilized the hyperparameter tuning
    process for our boosted decision tree in order to find the ideal
    parameters---such as learning rate and tree depth---for our data.

3.  As part of our model process (recipe and pre-processing), we check
    to ensure no variables have zero variance, add dummy variables for
    all categories which are not already encoded as such, and make sure
    to normalize all numeric predictors such that they are on a similar
    scale. These choices minimize the variance caused by outliers and
    differently categorized variables.

4.  We perform our model tuning process by generating a random grid of
    parameters and continually testing each hyperparameter under a
    different set of values. By measuring their performance, we
    continually update the hyper-parameters to the ones with the highest
    classified "accuracy" measure.

Ultimately, our Boosted Decision Tree consists of the following 8 tuning
parameter values [see Table \@ref(tab:example2)]:

```{=tex}
\begin{table}[ht]
  \centering
  \begin{tabular}{|c|c|c|}
    \hline
    Parameter Description & R Documentation & Value \\
    \hline
    Number of Randomly Selected Predictors & mtry & 17 \\
    Number of trees & trees & 98 \\
    Minimal Node Size & min$\_$n & 8 \\
    Tree Depth & tree$\_$depth & 9 \\
    Learning Rate & learn$\_$rate & $\approx$0.09885 \\
    Minimum Loss Reduction & loss$\_$reduction & $\approx$0 \\
    Sample Size & sample$\_$size & 1 \\
    Number of Iterations Before Stopping & stop$\_$iter & 5 \\
    \hline
  \end{tabular}
  \caption{Boosted Tree Tuning Parameters}
  \label{tab:example2}
\end{table}
```
From there, we perform a 10-fold cross-validation on our Boosted Tree
model to assess the stability of our parameters and ensure the
performance is consistent. As such, we randomly partition the original
sample into k equal-sized subsamples (folds), before testing and
training the model on each different iteration.

```{r model}
round_numbers <- 
  as.numeric(unique(players$pick_round[which(as.numeric(players$pick_round) %in% c(1:100))])) %>% 
  sort()

## Split the data into training and testing datasets
data <- players %>% 
  filter(home_state %in% tolower(state.abb)) %>% 
  select(-year, -mlb_played_first, -mlb_played_last, 
         -c(less_five_war:more_than_25), -birth_year) %>% 
  mutate(birth_state = tolower(person_birth_state_province),
         position = person_primary_position_abbreviation,
         .keep = "unused") %>%
  mutate(fWAR_class = factor(ifelse(fWAR >= 25, "Greater than 25 fWAR",
                             ifelse(fWAR >= 20 & fWAR < 25, "20-25 fWAR", 
                             ifelse(fWAR >= 15 & fWAR < 20, "15-20 fWAR", 
                                    ifelse(fWAR >= 10 & fWAR < 15, 
                                           "10-15 fWAR",
                                           ifelse(fWAR >= 5 & fWAR < 10, 
                                                  "5-10 fWAR",
                                           "Less than 5 fWAR") ) ) ) ), 
                             levels = c("Greater than 25 fWAR", "20-25 fWAR",
                                        "15-20 fWAR", "10-15 fWAR", "5-10 fWAR",
                                        "Less than 5 fWAR")),
         pick_round = factor(pick_round, levels = round_numbers),
         top_pick = factor(ifelse(pick_number == 1, 1, 0)),
         top_10 = factor(ifelse(pick_number <= 10, 1, 0)),
         top_25 = factor(ifelse(pick_number <= 25, 1, 0)),
         top_50 = factor(ifelse(pick_number <= 50, 1, 0)),
         top_100 = factor(ifelse(pick_number <= 100, 1, 0))) %>% 
  mutate_if(is.character, as.factor) %>% 
  drop_na()


# ## person_bat_side code tentative (will include anyways)
# ## All other 17 predictors confirmed important
# ## 29.77822 mins
# set.seed(1)
# boruta <-
#   Boruta(fWAR_class ~ pick_round + pick_number + person_height + person_weight +
#            home_state + person_bat_side_code + person_pitch_hand_code +
#            high_school + yrs_before_debut + debut_age + draft_age +
#            birth_state + position + top_pick + top_10 + top_25 + top_50 + 
#            top_100,
#          maxRuns = 250,
#          data = data)
# 
# # Extract the feature importance attributes
# boruta_feat_imp <- data.frame(attStats(boruta))
# boruta_feat_imp <- boruta_feat_imp %>%
#   arrange(desc(meanImp)) %>%
#   select(-normHits)
# # Select only the confirmed features of the tested variables
# boruta_feat <- getSelectedAttributes(boruta)
# paste0(boruta_feat, collapse = " + ")

set.seed(1)
data_split <- initial_split(data, prop = 0.70,
                            strata = position)
train <- training(data_split)
test <- testing(data_split)

# Create the fWAR classification Boosted Decision Tree
boost_model <- 
  boost_tree(mtry = 17,
             trees = 98,
             min_n = 8,
             tree_depth = 9,
             learn_rate = .0988522125906778,
             loss_reduction = 0.000000733510996319349,
             sample_size = c(1),
             stop_iter = c(5)) %>% 
  set_engine("xgboost") %>% 
  set_mode("classification")

### Used for tuning parameters
# boost_model <- 
#   boost_tree(mtry = tune(),
#              trees = tune(),
#              min_n = tune(),
#              tree_depth = tune(),
#              learn_rate = tune(),
#              loss_reduction = tune(),
#              sample_size = c(1),
#              stop_iter = c(5)) %>% 
#   set_engine("xgboost") %>% 
#   set_mode("classification")

# Create the + Recipe
boost_recipe <- 
  recipe(fWAR_class ~ pick_round + pick_number + person_height + person_weight +
           home_state + person_bat_side_code + person_pitch_hand_code +
           high_school + yrs_before_debut + debut_age + draft_age +
           birth_state + position + top_pick + top_10 + top_25 + top_50 + 
           top_100,
         data = train) %>%
  step_dummy(all_nominal(), -all_outcomes()) %>% 
  step_zv(all_predictors()) %>% 
  step_normalize(all_numeric_predictors())

# + Workflow
boost_wf <- 
  workflow() %>% 
  add_recipe(boost_recipe) %>% 
  add_model(boost_model)

set.seed(1)
boost_folds <- vfold_cv(train, v = 10) # Folds for cross-validation

# # Create a random grid of parameters for model tuning
# boost_grid <- grid_latin_hypercube(
#   mtry(range = c(5, 18)),
#   trees(range = c(25, 150)),
#   min_n(range = c(5, 15)),
#   tree_depth(range = c(5, 15)),
#   learn_rate(),
#   loss_reduction(),
#   size = 1500
# )

# Begin Parallel Processing
all_cores <- parallel::detectCores(logical = FALSE)
cl <- makePSOCKcluster(all_cores)
registerDoParallel(cl)


class_metrics <- metric_set(accuracy, roc_auc, f_meas)

# # Perform the tuning process
# boost_tune_res <- tune_grid(
#   boost_wf,
#   resamples = boost_folds,
#   grid = boost_grid,
#   control = control_grid(save_pred = TRUE),
#   metrics = class_metrics
# )

# best_parameters <- select_best(boost_tune_res, "accuracy")[, 1:6]

# # Update the + Model to the parameters with the "best" (lowest) RMSE
# boost_model <- 
#   finalize_model(boost_model, parameters = best_parameters)
# 
# 
# # Update the + Workflow
# boost_wf <- 
#   workflow() %>% 
#   add_recipe(boost_recipe) %>% 
#   add_model(boost_model)

# 10-fold Cross Validation
set.seed(1)
boost_crossval <-
  boost_wf %>% 
  tune::fit_resamples(resamples = boost_folds,
                metrics = class_metrics)

# Cross Validation Metrics
boost_metrics <- 
  boost_crossval %>% 
  collect_metrics()


# Fit the + Workflow to the Fastball Training Data
set.seed(1)
boost_fit <- 
  boost_wf %>% 
  fit(data = train)

# Make Predictions using the fitted + Model on the Testing Data
boost_predictions <- 
  boost_fit %>% 
  predict(test) %>%  
  rename(estimate = .pred_class) %>% 
  cbind(test$fWAR_class) %>% 
  rename(truth = `test$fWAR_class`)

conf_mat <-
  confusionMatrix(boost_predictions$estimate, boost_predictions$truth)

# Variable Importance Plot
vip_plot <- 
  boost_fit %>% 
  extract_fit_parsnip() %>% 
  vip(geom = "point") +
  labs(title = "Variable Importance Plot")
```

# Results

## Cross-Validation Metrics

After performing 10-fold cross-validation, we are able to measure the
accuracy of our model and determine its predictive power by constructing
the following metrics table. This does not specify the model's ability
to predict each individual WAR category, but rather computes the overall
accuracy for all classes.

```{r crossvalidation}
boost_metrics %>% 
  select(-.config) %>% 
  rename(metric = .metric,
         estimator = .estimator,
         folds = n,
         standard_error = std_err) %>% 
  mutate(mean = round(mean, digits = 4),
         standard_error = round(standard_error, digits = 4)) %>% 
  kbl(caption = "Table of Cross-Validation Metrics") %>% 
  kable_styling(latex_options = c("striped", "scale_down", "HOLD_position"))
```

According to our cross-validation metrics [see Table
\@ref(tab:crossvalidation)], our model perform moderately well. This is
because an accuracy of 78.47% is considered a "moderately accurate"
model, though we believe this is mostly caused by our model's
difficulties in distinguishing between classes. The `roc_auc` score
further shows that the model struggles to distinguish between the
positive and negative classes, as it is almost a 50-50 chance.

## Prediction Metrics by Class

Focusing on our models ability to predict each individual WAR category,
we calculate our model's sensitivity and detection rate for the
respective classes, alongside several other metrics.

```{r confusionMatrixbyClass}
conf_mat$byClass[, -c(3:6, 11)] %>% 
  round(digits = 3) %>% 
  kbl(caption = "Prediction Metrics by Class") %>% 
  kable_styling(latex_options = c("striped", "scale_down", "HOLD_position"))
```

Analyzing our model's prediction metrics according to each WAR category
[see Table \@ref(tab:confusionMatrixbyClass)], our model performs best
when predicting players with less than 5 fWAR and greatly suffers as it
increases. In other words, it is especially good at identifying players
who will perform below average (as seen by 0.987 Sensitivity and 0.766
Detection Rate). However, our model suffers when predicting players who
are average or better, as their detection rates are all 0%, with no
detection prevalence and sensitivity. There is some success when
predicting players with greater than 25 fWAR, but because the detection
rate is less than 1%, we do not believe that our model is very accurate
when identifying this category either.

## Confusion Matrix of Model Predictions

Because we are utilizing a classification algorithm, we construct a
confusion matrix to summarize the performance of our model, specifically
when predicting a player's success (WAR). The confusion matrix shows the
number of correct predictions, as expressed by the diagonal values.
Non-diagonal values are the number of incorrect classifications. The
rows signify the actual values, while the columns indicate the predicted
values. We use this table to identify which WAR categories our model
classifies correctly or incorrectly the most.

```{r confusionMatrixbyTotals}
conf_mat$table %>% 
  round(digits = 3) %>% 
  kbl(caption = "Confusion Matrix of Predictions") %>% 
  kable_styling(latex_options = c("striped", "scale_down", "HOLD_position"))
```

From our confusion matrix of model predictions [see Table
\@ref(tab:confusionMatrixbyTotals)], our model correctly classified 13
players as greater than 25 fWAR and 1605 as less than 5 fWAR. However,
it incorrectly classified 36 players who have a fWAR greater than 25,
and incorrectly classified 442 players who have a fWAR less than 5.
Overall, our model works best for predicting players with less than 5
fWAR, and signficantly lacks when predicting players with 5-25 fWAR.
There is some success for players with more than 25 fWAR, but it is not
accurate.

## Variable Importance Plot

Finally, we seek to identify which predictors are most important when
predicting a player's success or WAR. Using the results from our Boosted
Tree model, we rank each feature in the prediction process, and identify
whether or not they have a strong impact on a player's WAR.

```{r variableImportance, fig.cap="Variable Importance Plot", fig.height=6}
vip_plot
```

According to the variable importance plot [see Figure
\@ref(fig:variableImportance)], a player's debut age has the greatest
importance; this is followed by the number of years before their debut,
their pick number, their weight, height, age when drafted, and position.

These attributes are generally expected, as the age of a player at debut
and when they were drafted is often indicative of how much practice they
had before entering the major leagues. Furthermore, we generally expect
players who are drafted earlier to perform better, and certain physical
characteristics certainly affect their performance. Finally, we believe
that the position of a player influences their success [see Section
\@ref(what-positions-have-been-successful) for further information].

\newpage

# Conclusion

In this report, we are able to discover several important
characteristics when identifying MLB draft biases:

## High School vs. College Baseball Players Bias

The first of these biases is the bias towards drafting high school vs.
college baseball players. More often than not college players are
drafted more frequently, but this is likely due to the fact that teams
are more cautious with drafting high school players unless they're
exemplary. This is illustrated by the higher rate of high school players
being drafted in the rounds 1 through 5 than anywhere else in the draft.
This supports the idea that the high school players being drafted are
elite, and are being drafted very early on in the draft.

## Home State Bias

Another factor we were able to unlock was the draft bias for players
depending upon their home state. To no surprise players were most
frequently from larger states such as California, Texas, and Florida but
all states have high populations. Aside from this there was an affinity
for players hailing from states in warmer climates such as states in the
south, and states in the west. It's likely teams would be hesitant to
draft players from an underrepresented state like Vermont, or Wyoming
due to the lower talent pool, and the lack of history and certainty of
players from those areas historically.

## Relationship between Player Position and WAR

Using our metric for success as `fWAR` we were able to determine from
our statistical data concerning draft prospects who made the MLB that
those players who tend to succeed most in their careers are those
playing high leverage positions. These positions include third base
(3B), left field (LF), and center field (CF). Players at these positions
contribute drastic amounts of value in both their batting, and fielding
aspects of the game. These players tend to be overall strong players and
can contribute at most levels of the game. The other position which
stuck out was first base (1B), but first basemen rarely contribute
anything meaningful on the defensive side of the ball. First basemen
tend to have a more relaxed fielding responsibility but they tend to be
some of the best hitters all around. First basemen are known to be
phenomenal power hitters, and home runs and runs batted in are two of
the most valuable contributors to value in terms of `fWAR`.

## Impact of Player Attributes

Predicting a player's success based upon their draft information,
demographics, and characteristics proved to be a more difficult task.
While weight and height are important variables, we do not expect they
have a phenomenal performance as the beauty of baseball is described by
the randomness of the game.

## Model Results

We were able to produce a model with a cross-validated accuracy of about
78.5%. By no means is this accuracy low, but top performing accuracy
models will usually be in the mid 80s to higher in accuracy. The problem
lies with predicting which players will be performing at a high level.
The model was excellent at predicting the players who would perform
poorly in their careers (`fWAR_class`: "Less than 5 fWAR"), but
struggled at accurately predicting those who performed well during their
major league careers.

The meaningful outcome from the model lies in the variable importance of
the model constructed. It does not imply that all the variables are
truly important, but there are a few which likely do have a strong
impact on player success. There a 6 important variables we want to
highlight from the model: - `debut_age` - `yrs_before_debut` -
`pick_number` - `person_weight` - `person_height` - `draft_age`

\newpage

# Bibliography
